
name: Kind in podman

on:
  push:
  pull_request:
  workflow_dispatch:

jobs:
  kind-in-k8s:
    name: Kind in ${{ matrix.kubernetes }} / ${{ matrix.runtime }}
    runs-on: ubuntu-24.04${{ matrix.arch == 'arm64' && '-arm' || '' }}
    strategy:
      fail-fast: false
      matrix:
        arch: [ arm64 ]
        kubernetes: [ k3s, rke2, 'kubeadm init' ]
        runtime: [ cri-o, containerd ]
    timeout-minutes: 15
    steps:
      - uses: actions/checkout@v4
      - name: Install and setup CRI-O
        run: |
          CRIO_VERSION=v1.32
          curl -fsSL https://pkgs.k8s.io/addons:/cri-o:/stable:/$CRIO_VERSION/deb/Release.key \
              | gpg --dearmor | sudo tee /etc/apt/keyrings/cri-o-apt-keyring.gpg > /dev/null
          echo "deb [signed-by=/etc/apt/keyrings/cri-o-apt-keyring.gpg] https://pkgs.k8s.io/addons:/cri-o:/stable:/$CRIO_VERSION/deb/ /" \
              | sudo tee /etc/apt/sources.list.d/cri-o.list

          sudo apt update
          sudo apt install -y cri-o

          sudo rm -f /etc/cni/net.d/*.conflist
          sudo cp /etc/cni/net.d/10-crio-bridge.conflist.disabled /etc/cni/net.d/10-crio-bridge.conflist
          sudo systemctl start crio.service
        if: matrix.runtime == 'cri-o'
      - name: Setup the default containerd
        run: |
          sudo systemctl stop containerd || :

          curl -LO https://github.com/containerd/containerd/releases/download/v2.1.1/containerd-2.1.1-linux-$( dpkg --print-architecture ).tar.gz
          cat containerd-*.tar.gz | sudo bash -c 'cd /usr/local && tar xvzf -'

          curl -LO https://github.com/opencontainers/runc/releases/download/v1.3.0/runc.$( dpkg --print-architecture )
          sudo mv runc.* /usr/local/bin/runc
          sudo chmod a+x /usr/local/bin/runc

          sudo rm -f /etc/cni/net.d/*
          sudo cp 10-bridge.conflist /etc/cni/net.d/

          sudo mkdir -p /etc/containerd
          sudo cp containerd-config.toml /etc/containerd/config.toml

          curl -LO https://github.com/containerd/containerd/raw/refs/heads/main/containerd.service
          sudo mv containerd.service /etc/systemd/system/
          sudo systemctl daemon-reload

          sudo systemctl start containerd
          sudo ctr version
          diff -u <( sudo containerd config default ) <( sudo containerd config dump ) || true
        if: matrix.kubernetes == 'kubeadm init' && matrix.runtime == 'containerd'
      - name: Install and setup K3s
        run: |
          export INSTALL_K3S_EXEC
          if [ -e /var/run/crio/crio.sock ] ; then
              INSTALL_K3S_EXEC='--container-runtime-endpoint /var/run/crio/crio.sock'
          fi
          curl -sfL https://get.k3s.io | sh -s - --write-kubeconfig ~/.kube/config --write-kubeconfig-group $( id -g ) --write-kubeconfig-mode 640 --disable=traefik --disable=metrics-server
          if [ -e /var/run/crio/crio.sock ] ; then
              ( echo '[crio.network]' ; echo 'plugin_dirs = [ "/var/lib/rancher/k3s/data/cni" ]' ) | sudo tee /etc/crio/crio.conf.d/20-cni.conf
              sudo systemctl restart crio.service
          fi
        if: matrix.kubernetes == 'k3s'
      - name: Install and setup RKE2
        run: |
          sudo rm -f /etc/cni/net.d/*.conflist
          sudo mkdir -p /etc/rancher/rke2/config.yaml.d
          if [ -e /var/run/crio/crio.sock ] ; then
              echo 'container-runtime-endpoint: /var/run/crio/crio.sock' | sudo tee /etc/rancher/rke2/config.yaml.d/70-crio.yaml
          fi
          curl -sfL https://get.rke2.io | sudo sh -
          sudo systemctl start rke2-server.service
          systemctl status rke2-server.service

          mkdir ~/.kube
          sudo cat /etc/rancher/rke2/rke2.yaml > ~/.kube/config
          sudo ln -s /var/lib/rancher/rke2/bin/kubectl /usr/local/bin

          kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/master/deploy/local-path-storage.yaml

          while kubectl get pod -A 2>&1 | grep 'No resources found' ; do sleep 3 ; done
          kubectl get pod -A
          echo ---
          while kubectl get pod -A --no-headers | grep -v -E 'Running|Completed' ; do echo --- ; sleep 3 ; done
          kubectl get pod -A
        if: matrix.kubernetes == 'rke2'
      - name: Install and setup Kubernetes using kubeadm init
        run: |
          KUBERNETES_VERSION=v1.33
          curl -fsSL https://pkgs.k8s.io/core:/stable:/$KUBERNETES_VERSION/deb/Release.key \
              | gpg --dearmor | sudo tee /etc/apt/keyrings/kubernetes-apt-keyring.gpg > /dev/null
          echo "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/$KUBERNETES_VERSION/deb/ /" \
              | sudo tee /etc/apt/sources.list.d/kubernetes.list

          sudo apt update
          sudo apt install -y kubelet kubeadm kubectl kubernetes-cni

          sudo modprobe br_netfilter
          sudo sysctl -w net.ipv4.ip_forward=1
          sudo iptables -A FORWARD -o cni0 -j ACCEPT
          sudo iptables -A FORWARD -i cni0 -j ACCEPT

          if [ -e /var/run/crio/crio.sock ] ; then
              CONFIG=k8s-initconfiguration-crio.yaml
          else
              CONFIG=k8s-initconfiguration-containerd.yaml
          fi
          sudo kubeadm init --config $CONFIG

          mkdir ~/.kube
          sudo cp -f /etc/kubernetes/admin.conf $HOME/.kube/config
          sudo chown $( id -u ):$( id -g ) ~/.kube/config

          kubectl taint nodes $( hostname ) node-role.kubernetes.io/control-plane:NoSchedule-
          kubectl apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/master/deploy/local-path-storage.yaml
        if: matrix.kubernetes == 'kubeadm init'

      - name: Build image
        run: docker build -t localhost/kind .
      - run: sudo skopeo copy docker-daemon:localhost/kind:latest containers-storage:localhost/kind
        if: matrix.runtime == 'cri-o'
      - run: docker save localhost/kind | sudo k3s ctr images import -
        if: matrix.kubernetes == 'k3s' && matrix.runtime == 'containerd'
      - run: docker save localhost/kind | sudo /var/lib/rancher/rke2/bin/ctr --address /run/k3s/containerd/containerd.sock -n k8s.io images import -
        if: matrix.kubernetes == 'rke2' && matrix.runtime == 'containerd'
      - run: docker save localhost/kind | sudo ctr -n k8s.io images import -
        if: matrix.kubernetes == 'kubeadm init' && matrix.runtime == 'containerd'
      - run: sudo systemctl stop docker.service docker.socket

      - name: Wait for the cluster to become ready
        run: while ! kubectl get nodes | grep . ; do sleep 5 ; done ; kubectl wait node --all --for=condition=ready --timeout=240s
      - run: kubectl get all -A ; kubectl rollout status deployment --namespace=kube-system --timeout=240s ; kubectl wait pod -A --all --for=condition=Ready --timeout=240s ; kubectl get all -A
      - run: while ! kubectl get serviceaccount/default ; do sleep 5 ; done
      - run: kubectl apply -f - < kind-cluster-pod.yaml
      - run: while ! kubectl get pod/kind-cluster -o jsonpath="{.status.initContainerStatuses[0].state['running','terminated'].startedAt}" | grep . ; do kubectl get pod/kind-cluster ; sleep 5 ; done
      - run: kubectl logs -f pod/kind-cluster -c create-cluster
      - run: kubectl describe pod/kind-cluster
      - run: kubectl get pod/kind-cluster -o jsonpath="{.status.initContainerStatuses[0].state['terminated'].exitCode}" | grep ^0$
      - run: while ! kubectl get pod/kind-cluster -o jsonpath="{.status.containerStatuses[0].state['running','terminated'].startedAt}" | grep . ; do kubectl get pod/kind-cluster ; sleep 5 ; done
      - run: kubectl logs pod/kind-cluster
      - run: kubectl get pod/kind-cluster
      - run: kubectl describe pod/kind-cluster
      - run: kubectl exec pod/kind-cluster -- podman ps -a
      - run: while ! kubectl exec pod/kind-cluster -- curl -ks https://127.0.0.1:6443/ ; do sleep 1 ; done
      - run: kubectl exec pod/kind-cluster -- kubectl get nodes -o jsonpath='{.items[*].metadata.name}' | xargs kubectl exec pod/kind-cluster -- kubectl wait --for=condition=ready node
      - run: kubectl exec pod/kind-cluster -- kubectl get nodes
      - run: kubectl exec pod/kind-cluster -- kubectl get all -A

      - run: kubectl exec pod/kind-cluster -- kubectl create serviceaccount -n default admin
      - run: kubectl exec pod/kind-cluster -- kubectl patch clusterrolebinding cluster-admin --type=json -p='[{"op":"add", "path":"/subjects/-", "value":{"kind":"ServiceAccount", "namespace":"default", "name":"admin" } }]'
      - run: kubectl --kubeconfig=./kubeconfig config set-cluster kind --server=https://$( kubectl get service/kind-cluster -o jsonpath='{.spec.clusterIP}:{.spec.ports[0].port}' ) --insecure-skip-tls-verify=true
      - run: kubectl --kubeconfig=./kubeconfig config set-credentials kind-admin --token=$( kubectl exec pod/kind-cluster -- kubectl create token -n default admin )
      - run: kubectl --kubeconfig=./kubeconfig config set-context kind --cluster=kind --user=kind-admin
      - run: kubectl --kubeconfig=./kubeconfig config use-context kind
      - run: kubectl --kubeconfig=./kubeconfig get all -A

      - run: kubectl delete pod/kind-cluster
      - run: kubectl apply -f - < kind-cluster-pod.yaml
      - run: while ! kubectl get pod/kind-cluster -o jsonpath="{.status.containerStatuses[0].state['running','terminated'].startedAt}" | grep . ; do kubectl get pod/kind-cluster ; sleep 5 ; done
      - run: kubectl logs pod/kind-cluster -c create-cluster
      - run: kubectl logs pod/kind-cluster
      - run: while ! kubectl exec pod/kind-cluster -- curl -ks https://127.0.0.1:6443/ ; do sleep 1 ; done
      - run: kubectl exec pod/kind-cluster -- kubectl get all -A

      - run: kubectl --kubeconfig=./kubeconfig get all -A

      - name: Setup upterm session
        uses: lhotari/action-upterm@v1
        if: failure()
