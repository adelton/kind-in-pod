
name: Kind in podman

on:
  push:
  pull_request:
  workflow_dispatch:

jobs:
  kind-in-podman:
    name: Kind
    runs-on: ubuntu-24.04${{ matrix.arch == 'arm64' && '-arm' || '' }}
    strategy:
      fail-fast: false
      matrix:
        arch: [ amd64, arm64 ]
        style: [ rootless, rootful ]
        inner-podman-version: [ v5.4, v5.5 ]
        exclude:
          - arch: amd64
            style: rootful
    timeout-minutes: 15
    env:
      kind_create_opts: --config /etc/kind-cluster.yaml
    steps:
      - uses: actions/checkout@v4
      - name: Set podman env
        run: echo "podman=podman" >> $GITHUB_ENV
      - name: Set sudo podman env
        run: echo "podman=sudo podman" >> $GITHUB_ENV
        if: matrix.style == 'rootful'
      - name: Enable cpu cgroup delegation
        run: |
          for i in /sys/fs/cgroup/user.slice/cgroup.subtree_control \
            /sys/fs/cgroup/user.slice/user-$(id -u).slice/cgroup.subtree_control \
            /sys/fs/cgroup/user.slice/user-$(id -u).slice/user@$(id -u).service/cgroup.subtree_control ; do \
            echo '+cpu' | sudo tee -a $i ; \
          done
        if: matrix.style == 'rootless'
      - name: Use podman ${{ matrix.inner-podman-version }} in the container
        run: sed -i 's%^FROM quay\.io/podman/stable.*%FROM quay.io/podman/stable:${{ matrix.inner-podman-version }}%' Dockerfile
      - name: Build image
        run: $podman build -t localhost/kind .
      - name: Create a volume
        run: $podman volume create kind-data
      - name: Network definition for rootless
        run: echo "podman_run_opts=-v $(pwd)/kind-network.yaml:/var/lib/containers/storage/networks/kind.json" >> $GITHUB_ENV
        if: matrix.style == 'rootless'
      - name: Network definition for rootful
        run: echo "podman_run_opts=-v $(pwd)/kind-network.yaml:/etc/containers/networks/kind.json" >> $GITHUB_ENV
        if: matrix.style == 'rootful'
      - name: Run the podman container
        run: $podman run -d --privileged --read-only --name kind -v kind-data:/var/lib/containers $podman_run_opts -p 6443:6443 localhost/kind
      - name: Cluster configuration for rootless
        run: echo "kind_create_opts=--config /etc/kind-cluster-rootless.yaml" >> $GITHUB_ENV
        if: matrix.style == 'rootless'
      - name: Create kind cluster
        run: $podman exec kind kind create cluster --retain $kind_create_opts
      - run: $podman exec kind podman logs kind-control-plane
        if: ${{ failure() }}
      - run: $podman exec kind kubectl cluster-info --context kind-kind
      - run: $podman exec -ti kind kubectl wait --for=condition=ready -n kube-system pod/etcd-kind-control-plane pod/kube-apiserver-kind-control-plane --timeout=60s
      - run: $podman exec kind kubectl get nodes -o jsonpath='{.items[*].metadata.name}' | xargs $podman exec kind kubectl wait --for=condition=ready node
      - run: $podman exec kind kubectl get nodes
      - run: $podman exec kind kubectl get all -A
      - run: |
          $podman exec kind curl -sk https://127.0.0.1:6443/ | tee /dev/stderr | grep -q 'forbidden: User \\"system:anonymous\\" cannot get path'
      - run: |
          curl -s --cacert <( $podman exec kind bash -c 'cat $KUBECONFIG' | awk '/certificate-authority-data:/ { print $2 }' | base64 -d ) https://127.0.0.1:6443/ | tee /dev/stderr | grep -q 'forbidden: User \\"system:anonymous\\" cannot get path'
      - run: curl -s --cacert <( $podman exec kind bash -c 'cat $KUBECONFIG' | awk '/certificate-authority-data:/ { print $2 }' | base64 -d ) -E <( $podman exec kind bash -c 'cat $KUBECONFIG' | awk '/client-certificate-data:/ { print $2 }' | base64 -d ) --key <( $podman exec kind bash -c 'cat $KUBECONFIG' | awk '/client-key-data:/ { print $2 }' | base64 -d ) https://127.0.0.1:6443/ | tee /dev/stderr | grep -Fq /apis/authentication.k8s.io/v1
      - run: $podman rm -f kind
      - run: $podman run -d --privileged --read-only --name kind -v kind-data:/var/lib/containers $podman_run_opts -p 6443:6443 localhost/kind
      - run: $podman exec -ti kind podman start --all
      - run: $podman exec -ti kind podman wait --condition=running kind-control-plane ; sleep 10
      - run: $podman exec kind kubectl get all -A

  kind-in-k3s:
    name: Kind in K3s
    runs-on: ubuntu-24.04${{ matrix.arch == 'arm64' && '-arm' || '' }}
    strategy:
      fail-fast: false
      matrix:
        arch: [ amd64, arm64 ]
        runtime: [ cri-o, default ]
    timeout-minutes: 15
    steps:
      - uses: actions/checkout@v4
      - name: Install and setup CRI-O
        run: |
          CRIO_VERSION=v1.32
          curl -fsSL https://pkgs.k8s.io/addons:/cri-o:/stable:/$CRIO_VERSION/deb/Release.key \
              | gpg --dearmor | sudo tee /etc/apt/keyrings/cri-o-apt-keyring.gpg > /dev/null
          echo "deb [signed-by=/etc/apt/keyrings/cri-o-apt-keyring.gpg] https://pkgs.k8s.io/addons:/cri-o:/stable:/$CRIO_VERSION/deb/ /" \
              | sudo tee /etc/apt/sources.list.d/cri-o.list

          sudo apt update
          sudo apt install -y cri-o

          sudo cp /etc/cni/net.d/10-crio-bridge.conflist.disabled /etc/cni/net.d/10-crio-bridge.conflist
          sudo systemctl start crio.service
        if: matrix.runtime == 'cri-o'
      - name: Install and setup K3s
        run: |
          export INSTALL_K3S_EXEC
          if [ -e /var/run/crio/crio.sock ] ; then
              INSTALL_K3S_EXEC='--container-runtime-endpoint /var/run/crio/crio.sock'
          fi
          curl -sfL https://get.k3s.io | sh -s - --write-kubeconfig ~/.kube/config --write-kubeconfig-group $( id -g ) --write-kubeconfig-mode 640 --disable=traefik --disable=metrics-server
          if [ -e /var/run/crio/crio.sock ] ; then
              ( echo '[crio.network]' ; echo 'plugin_dirs = [ "/var/lib/rancher/k3s/data/cni" ]' ) | sudo tee /etc/crio/crio.conf.d/20-cni.conf
              sudo systemctl restart crio.service
          fi
      - name: Build image
        run: docker build -t localhost/kind .
      - run: sudo skopeo copy docker-daemon:localhost/kind:latest containers-storage:localhost/kind
        if: matrix.runtime == 'cri-o'
      - run: docker save localhost/kind | sudo k3s ctr images import -
        if: matrix.runtime == 'default'
      - run: sudo systemctl stop docker.service docker.socket

      - name: Wait for the cluster to become ready
        run: while ! kubectl get nodes ; do sleep 5 ; done ; kubectl get nodes -o jsonpath='{.items[*].metadata.name}' | xargs kubectl wait --for=condition=ready node
      - run: kubectl get all -A
      - run: while ! kubectl get serviceaccount/default ; do sleep 5 ; done
      - run: kubectl apply -f - < kind-cluster-pod-k3s.yaml
      - run: while ! kubectl get pod/kind-cluster -o jsonpath="{.status.initContainerStatuses[0].state['running','terminated'].startedAt}" | grep . ; do kubectl get pod/kind-cluster ; sleep 5 ; done
      - run: kubectl logs -f pod/kind-cluster -c create-cluster
      - run: kubectl describe pod/kind-cluster
      - run: kubectl get pod/kind-cluster -o jsonpath="{.status.initContainerStatuses[0].state['terminated'].exitCode}" | grep ^0$
      - run: while ! kubectl get pod/kind-cluster -o jsonpath="{.status.containerStatuses[0].state['running','terminated'].startedAt}" | grep . ; do kubectl get pod/kind-cluster ; sleep 5 ; done
      - run: kubectl logs pod/kind-cluster
      - run: kubectl get pod/kind-cluster
      - run: kubectl describe pod/kind-cluster
      - run: kubectl exec pod/kind-cluster -- podman ps -a
      - run: while ! kubectl exec pod/kind-cluster -- curl -ks https://127.0.0.1:6443/ ; do sleep 1 ; done
      - run: kubectl exec pod/kind-cluster -- kubectl get nodes -o jsonpath='{.items[*].metadata.name}' | xargs kubectl exec pod/kind-cluster -- kubectl wait --for=condition=ready node
      - run: kubectl exec pod/kind-cluster -- kubectl get nodes
      - run: kubectl exec pod/kind-cluster -- kubectl get all -A

      - run: kubectl exec pod/kind-cluster -- kubectl create serviceaccount -n default admin
      - run: kubectl exec pod/kind-cluster -- kubectl patch clusterrolebinding cluster-admin --type=json -p='[{"op":"add", "path":"/subjects/-", "value":{"kind":"ServiceAccount", "namespace":"default", "name":"admin" } }]'
      - run: kubectl --kubeconfig=./kubeconfig config set-cluster kind --server=https://$( kubectl get service/kind-cluster -o jsonpath='{.spec.clusterIP}:{.spec.ports[0].port}' ) --insecure-skip-tls-verify=true
      - run: kubectl --kubeconfig=./kubeconfig config set-credentials kind-admin --token=$( kubectl exec pod/kind-cluster -- kubectl create token -n default admin )
      - run: kubectl --kubeconfig=./kubeconfig config set-context kind --cluster=kind --user=kind-admin
      - run: kubectl --kubeconfig=./kubeconfig config use-context kind
      - run: kubectl --kubeconfig=./kubeconfig get all -A

      - run: kubectl delete pod/kind-cluster
      - run: kubectl apply -f - < kind-cluster-pod-k3s.yaml
      - run: while ! kubectl get pod/kind-cluster -o jsonpath="{.status.containerStatuses[0].state['running','terminated'].startedAt}" | grep . ; do kubectl get pod/kind-cluster ; sleep 5 ; done
      - run: kubectl logs pod/kind-cluster -c create-cluster
      - run: kubectl logs pod/kind-cluster
      - run: while ! kubectl exec pod/kind-cluster -- curl -ks https://127.0.0.1:6443/ ; do sleep 1 ; done
      - run: kubectl exec pod/kind-cluster -- kubectl get all -A

      - run: kubectl --kubeconfig=./kubeconfig get all -A

